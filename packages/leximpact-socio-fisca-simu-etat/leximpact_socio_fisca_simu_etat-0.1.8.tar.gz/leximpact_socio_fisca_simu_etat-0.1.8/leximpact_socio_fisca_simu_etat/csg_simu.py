# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/simu_budget.ipynb (unless otherwise specified).

__all__ = [
    "plf_2022",
    "config",
    "aggregates",
    "cache",
    "tc",
    "SimulationError",
    "inputfile_path",
    "sample_pop",
    "convert_erfr_to_openfisca",
    "sample_pop",
    "individus_to_foyer_fiscaux",
    "sample_pop_foyer",
    "create_simulation",
    "CustomReform",
    "rounddown",
    "compute_quantile",
    "quantile_to_df",
    "compute_reform",
    "compute_all_simulation",
]

import hashlib
import json

# Cell
# For profiling of code
import timeit
import unittest

# import warnings
from typing import Dict, List

import numpy as np
import pandas as pd
from openfisca_core import periods

# from openfisca_core.memory_config import MemoryConfig
from openfisca_core.parameters import ParameterNode, ParameterScaleBracket, helpers
from openfisca_core.periods import instant
from openfisca_core.simulation_builder import SimulationBuilder
from openfisca_core.taxbenefitsystems import TaxBenefitSystem  # For typing

# from openfisca_core.warnings import MemoryConfigWarning, TempfileWarning
from openfisca_france import FranceTaxBenefitSystem
from openfisca_france.model.base import Reform
from openfisca_france_reforms.plf_2022 import Plf2022

from .aggregates_read import Aggregate
from .cache import Cache
from .config import Configuration
from .logger import logger
from .schema import AllSimulationResult, OneSimulationResult, ReformeSocioFiscale

# Cell


plf_2022 = Plf2022(FranceTaxBenefitSystem())

config = Configuration()
aggregates = Aggregate(config.get("AGREGATS"))
cache = Cache()
tc = unittest.TestCase()

# Cell


class SimulationError(Exception):
    """Custom error"""

    pass


# Cell

inputfile_path = config.get("ERFS_FINAL_FOR_SIMU")
# inputfile_path = config.get("ERFS_FINAL_FOR_SIMU_PLF_2022")
sample_pop = pd.read_hdf(inputfile_path)

# Cell
for v in [
    "assiette_csg_abattue",
    "assiette_csg_non_abattue",
    "csg_imposable_salaire",
    "csg_deductible_salaire",
    "csg_imposable_retraite",
    "csg_deductible_retraite",
    "csg_imposable_chomage",
    "csg_deductible_chomage",
    "csg_revenus_capital",
    "crds_salaire",
    "crds_retraite",
    "crds_chomage",
    "crds_revenus_capital",
    "irpp",
]:
    tc.assertFalse(
        v in sample_pop.columns,
        f"FATAL : {v} is in the input dataset, please remove output variables from the input dataset !",
    )

# Cell


def convert_erfr_to_openfisca(data):
    """
    # Conversion des noms ERFS en noms  OpenFisca
    Traduction des roles attribués au format openfisca
    ::data:: Le dataset à convertir
    """
    data["quimenof"] = "enfant"
    data.loc[data["quifoy"] == 1, "quimenof"] = "conjoint"
    data.loc[data["quifoy"] == 0, "quimenof"] = "personne_de_reference"

    data["quifoyof"] = "personne_a_charge"
    data.loc[data["quifoy"] == 1, "quifoyof"] = "conjoint"
    data.loc[data["quifoy"] == 0, "quifoyof"] = "declarant_principal"

    data["quifamof"] = "enfant"
    data.loc[data["quifam"] == 1, "quifamof"] = "conjoint"
    data.loc[data["quifam"] == 0, "quifamof"] = "demandeur"
    return data


# Cell

sample_pop = convert_erfr_to_openfisca(sample_pop)

# Cell


def individus_to_foyer_fiscaux(sample_individus):
    """
    Regroupe un échantillon par individus en échantillon par foyers fiscaux
    """
    # On regroupe les individus de sample_pop_individus en foyers fiscaux par leur idfoy
    sample_foyers_fiscaux = sample_individus.groupby(
        ["idfoy", "wprm"], as_index=False
    ).sum()
    # On supprime les colonnes qui n'ont plus de sens au niveau foyer
    sample_foyers_fiscaux.drop(
        [
            "quifoy",
            "quifam",
            "age",
            "categorie_salarie",
            "contrat_de_travail",
            "statut_marital",
        ],
        axis=1,
        inplace=True,
    )

    return sample_foyers_fiscaux


# Cell

sample_pop_foyer = individus_to_foyer_fiscaux(sample_pop)

# Cell
# sample_pop_foyer = pd.read_csv(config["DATA_OUT"] + "sample_pop_ff_csg.csv")
# annee_de_calcul = "2021"

# Cell

# Remove warnings about using disk cache in case of Out of Memory
# warnings.simplefilter(action="ignore", category=MemoryConfigWarning)
# warnings.simplefilter(action="ignore", category=TempfileWarning)


def create_simulation(period: str, data: pd.DataFrame, tbs: TaxBenefitSystem):
    # Vient de LexImpact Server simulate_pop_from_reform-> simulation
    sb = SimulationBuilder()
    sb.create_entities(tbs)

    sb.declare_person_entity("individu", data.index)

    # Creates openfisca entities and generates grouped

    listentities = {"foy": "foyer_fiscal", "men": "menage", "fam": "famille"}

    instances = {}
    dictionnaire_datagrouped = {"individu": data}

    for ent, ofent in listentities.items():
        persons_ent = data["id" + ent].values
        persons_ent_roles = data["qui" + ent + "of"].values
        ent_ids = data["id" + ent].unique()
        instances[ofent] = sb.declare_entity(ofent, ent_ids)
        sb.join_with_persons(instances[ofent], persons_ent, roles=persons_ent_roles)

        # The following ssumes data defined for an entity are the same for all rows in
        # the same entity. Or at least that the first non null value found for an
        # entity will always be the total value for an entity (which is the case for
        # f4ba). These checks are performed in the checkdata function defined below.
        dictionnaire_datagrouped[ofent] = (
            data.groupby("id" + ent, as_index=False).first().sort_values(by="id" + ent)
        )

    # These variables should not be attributed to any OpenFisca Entity
    columns_not_OF_variables = {
        "idmen",
        "idfoy",
        "idfam",
        "noindiv",
        "level_0",
        "quifam",
        "quifoy",
        "quimen",
        "idmen_x",
        "idmen_y",
        "wprm",
        "index",
        "idmen_original",
        "idfoy_original",
        "idfam_original",
        "quifamof",
        "quifoyof",
        "quimenof",
        "assiette_csg_plus_values",
        "csg_deductible_chomage",
        "csg_imposable_chomage",
        "csg_chomage",
        "csg_deductible_retraite",
        "csg_imposable_retraite",
        "csg_retraite",
        "pote_rev_capital",
        "pote_rente_viagere",
        "pote_rev_categ_foncier",
        "pote_plus_values",
        "pote_chomage",
        "pote_retraite",
        "pote_pre-retraite",
        "fake_id",
        "taux_csg_remplacement",
    }

    simulation = sb.build(tbs)
    #     memory_config = MemoryConfig(
    #         max_memory_occupation=0.95,  # When 95% of the virtual memory is full, switch to disk storage
    #         priority_variables=["salary", "age"],  # Always store these variables in memory
    #         # variables_to_drop=non_cached_variables,
    #     )
    #     simulation.memory_config = memory_config

    # Attribution des variables à la bonne entité OpenFisca
    for colonne in data.columns:
        # On entre les valeurs sur les 3 dernieres annees (par exemple pour calculer la retraite)
        for year in range(int(period) - 2, int(period) + 1):
            if colonne not in columns_not_OF_variables:
                try:
                    # print("colonne", colonne)
                    simulation.set_input(
                        colonne,
                        str(year),
                        dictionnaire_datagrouped[tbs.get_variable(colonne).entity.key][
                            colonne
                        ],
                    )
                except AttributeError as e:
                    print(
                        f"AttributeError, are you sure {colonne} is known by your OpenFisca TaxBenefitSystem ? {e}"
                    )
                    raise e

    return simulation, dictionnaire_datagrouped


# Cell
class CustomReform(Reform):
    """
    Override the OpenFisca Reform class
    """

    def __init__(
        self, tbs: TaxBenefitSystem, payload: ReformeSocioFiscale, period: str
    ) -> None:
        self.payload = payload
        self.instant = periods.instant(period)
        self.period = periods.period("year:1900:200")
        # logger.debug(f"CustomReform.init period : {self.period}")
        super().__init__(tbs)

    def modifier(self, parameters: ParameterNode) -> ParameterNode:
        # openfisca-france/openfisca_france/parameters/prelevements_sociaux/contributions_sociales/csg/
        if self.payload.amendement is None:
            return parameters
        for parameter_name, change in self.payload.amendement.items():
            # On itère sur chaque partie du nom du paramètre en str pour en faire un ParameterNode conforme
            parameter = parameters
            for sub_name in parameter_name.split("."):
                parameter = parameter.children[sub_name]
            # Si la valeur est un dictionnaire, alors on a affaire à un barème, ou un paramètre avec plage de date.
            if isinstance(change, Dict):
                # logger.debug(f"la valeur est un dictionnaire, on a affaire à un barème, change:{change}")
                if change["type"] == "parameter":
                    taux = change["value"]
                    parameter.update(
                        start=instant(change.get("start")),
                        stop=instant(change.get("stop")),
                        value=taux,
                    )
                elif change["type"] == "scale":
                    # ### Debut du copier-coller de https://git.leximpact.dev/leximpact/leximpact-socio-fiscal-api/-/blob/master/leximpact_socio_fiscal_api/routers/simulations.py#L62
                    # TODO: handle stop?.
                    if change.get("stop") is not None:
                        logger.error(
                            "CustomReform : Scale change can't contain a 'stop' !"
                        )
                        break
                    # Note: change has the form:
                    # {
                    #     'scale': [
                    #         {'rate': {'value': 0.5}, 'threshold': {'value': 0}},
                    #         {'rate': {'value': 0}, 'threshold': {'value': 4}},
                    #     ],
                    #     'start': '2021-01-01',
                    #     'type': 'scale',
                    # }
                    # This is not the same structure as OpenFisca brackets
                    # => Convert it.
                    brackets = parameter.brackets
                    value_key = (
                        "amount"
                        if any("amount" in bracket.children for bracket in brackets)
                        else "average_rate"
                        if any(
                            "average_rate" in bracket.children for bracket in brackets
                        )
                        else "rate"
                    )

                    brackets_change = []
                    for bracket in change["scale"]:
                        bracket_change = {}

                        threshold = bracket["threshold"]
                        if threshold == "expected":
                            logger.error(
                                "Brackets with 'expected' values are not supported."
                            )
                            break
                        value = threshold["value"]
                        if value is None:
                            # Ignore brackets with a null threshold.
                            continue
                        bracket_change["threshold"] = value

                        if value_key == "amount":
                            amount = bracket["amount"]
                            if amount == "expected":
                                logger.error(
                                    "Brackets with 'expected' values are not supported."
                                )
                                break
                            bracket_change["amount"] = amount["value"]
                        elif value_key == "average_rate":
                            rate = bracket["rate"]
                            if rate == "expected":
                                logger.error(
                                    "Brackets with 'expected' values are not supported."
                                )
                                break
                            bracket_change["average_rate"] = rate["value"]
                        else:
                            base = bracket.get("base")
                            if base is not None:
                                if base == "expected":
                                    logger.error(
                                        "Brackets with 'expected' values are not supported."
                                    )
                                    break
                                bracket_change["base"] = base["value"]
                            rate = bracket["rate"]
                            if rate == "expected":
                                logger.error(
                                    "Brackets with 'expected' values are not supported."
                                )
                                break
                            bracket_change["rate"] = rate["value"]
                        brackets_change.append(bracket_change)
                    else:
                        # Brackets change contains no error.
                        brackets_change.sort(
                            key=lambda bracket_change: bracket_change["threshold"]
                        )
                        start = change["start"]
                        for index, bracket_change in enumerate(brackets_change):
                            if len(brackets) <= index:
                                brackets.append(
                                    ParameterScaleBracket(
                                        name=helpers._compose_name(
                                            parameter.name, item_name=index
                                        ),
                                        data={
                                            key: {start: value_change}
                                            for key, value_change in bracket_change.items()
                                        },
                                    )
                                )
                            else:
                                bracket_dict = brackets[index].children
                                for key, value_change in bracket_change.items():
                                    value = bracket_dict.get(key)
                                    if value is None:
                                        bracket_dict[key] = dict(
                                            start=instant(start),
                                            value=value_change,
                                        )
                                    else:
                                        value.update(
                                            start=instant(start),
                                            value=value_change,
                                        )
                        if len(brackets) > len(brackets_change):
                            del brackets[len(brackets_change) :]
                # #### Fin du copier-coller
                else:
                    logger.error(
                        f'Parameter type {value["type"]} not yet implemented in our API.'
                    )
                    # TODO : raise exception ?
                # print(parameter.brackets[0].children['rate'].__dict__)
            else:
                # Si ce n'est pas un barème, on update la valeur du paramètre

                parameter.update(period=self.period, value=change)
                # logger.debug(f"CustomReform.modifier parameter {parameter_name} for {self.period} after update : {parameter}",)
        return parameters

    def apply(self) -> None:
        self.modify_parameters(modifier_function=self.modifier)


# Cell
def rounddown(number):
    """
    Met à 0 60% des chiffres pour ne pas remonter de valeurs personnelles
    """
    number = int(number)
    s = list(str(number))
    for i in range(len(s)):
        if i < 2 or i < len(s) * 0.4:
            continue
        s[i - len(s)] = "0"
    return int("".join(s))


# Cell
def compute_quantile(
    df: pd.DataFrame(),
    quantile_base_variable: List[str],
    col_values: List[str],
    nb_quantiles=10,
    do_rounddown=True,
    only_above_zero=False,
) -> List[Dict[str, float]]:
    max_quantiles = 20
    if nb_quantiles > max_quantiles:
        msg = f"Sorry, we need to protect the secret of the data. Only {max_quantiles} quantiles maximum allowed."
        logger.error(msg)
        raise SimulationError(msg)
    if nb_quantiles >= len(df):
        msg = "Sorry, not enougth data."
        logger.error(msg)
        raise SimulationError(msg)
    if quantile_base_variable is None:
        msg = "quantile_base_variable is mandatory for quantile."
        logger.warning(msg)
        raise SimulationError(msg)
    for c in quantile_base_variable:
        if c in col_values:
            msg = "Columns in quantile_base_variable and col_values must be distinct"
            logger.warning(msg)
            raise SimulationError(msg)
    # print("avant\n",df)
    # Add columns of quantile_base_variable
    df_for_quantile = df

    # If we have weighted data
    if "wprm" in df_for_quantile.columns:
        for col in col_values:
            df_for_quantile[col + "_wprm"] = (
                df_for_quantile["wprm"] * df_for_quantile[col]
            )
    quantile_base_column_name = "+".join(quantile_base_variable)
    quantile_base_col_name = "new_temp_column_to_compute_qsgf654e6gq"
    df_for_quantile[quantile_base_col_name] = 0.0
    for col in quantile_base_variable:
        df_for_quantile[quantile_base_col_name] = (
            df_for_quantile[quantile_base_col_name] + df_for_quantile[col]
        )
    if only_above_zero:
        df_for_quantile = df_for_quantile.query(quantile_base_col_name + " > 0")
    # Compute quantile base
    # df_for_quantile = df_for_quantile[[quantile_base_col_name] + col_values]
    df_for_quantile = df_for_quantile.sort_values(
        [quantile_base_col_name], ascending=True
    )
    df_for_quantile.reset_index(inplace=True)
    # print("apres ajout colonne\n", df_for_quantile)
    nb_lignes = len(df_for_quantile)
    quantile_fraction = [(1 / nb_quantiles) * (i + 1) for i in range(nb_quantiles)]
    seuil_inf = 0
    quantiles_list = []
    for f in quantile_fraction:
        seuil_supp = (
            int(nb_lignes * f)
            if nb_lignes - int(nb_lignes * f) >= nb_lignes * quantile_fraction[0]
            else nb_lignes
        )
        df_tranche = df_for_quantile.loc[seuil_inf:seuil_supp]
        # print(f"{f*100:.0f} percentile {seuil_inf=} {seuil_supp=} {len(df_tmp)=} {df_tmp[quantile_base_col_name].sum():,=} {df_tmp.csg.sum():,=}")
        # print(df_tmp)
        upper_value = (
            rounddown(df_tranche.iloc[-1][quantile_base_col_name])
            if do_rounddown
            else df_tranche.iloc[-1][quantile_base_col_name]
        )

        count = (
            df_tranche.wprm.sum() if "wprm" in df_tranche.columns else len(df_tranche)
        )
        un_quantile = {
            "fraction": f,
            "count": count,
            quantile_base_column_name: upper_value,
        }
        # print("quantile_base_column_name", un_quantile.get(quantile_base_column_name))
        sum_tmp = 0
        for v in col_values:
            un_quantile[v] = (
                df_tranche[v + "_wprm"].sum()
                if "wprm" in df_tranche.columns
                else df_tranche[v].sum()
            )
            sum_tmp += un_quantile[v]
        if len(col_values) > 1:
            un_quantile["+".join(col_values)] = sum_tmp
        quantiles_list.append(un_quantile)
        seuil_inf = seuil_supp + 1  # if seuil_inf != 0 else seuil_supp

    return quantiles_list


# Cell


def quantile_to_df(resultat_quantile, variable):
    df_base = pd.DataFrame(resultat_quantile.result["base"].quantiles)
    df_plf = pd.DataFrame(resultat_quantile.result["plf"].quantiles)
    df_amendement = pd.DataFrame(resultat_quantile.result["amendement"].quantiles)
    df_base["plf"] = df_plf[variable]
    df_base["amendement"] = df_amendement[variable]
    df_base["avant"] = df_base[variable]
    return df_base


# Cell


def compute_reform(
    reformParameters: ReformeSocioFiscale,
    annee_de_calcul: str,
    ignore_recallage=False,
    tax_benefit_system=FranceTaxBenefitSystem(),
    only_above_zero=True,
) -> (OneSimulationResult, List[str]):
    """
    ::reformOpenFisca:: OpenFisca Reform class to use
    ::reformParameters:: OpenFisca parameters to apply.
    ::annee_de_calcul:: Année de calcul pour OpenFisca
    ::ignore_recallage:: Si on ne souhaite pas recaller les données
    """
    errors = []
    simu_out = OneSimulationResult(state_budget={"error": 1.0})
    # logger.debug(f"reformParameters.amendement : {reformParameters.amendement}")
    # logger.debug(f"compute_reform - reformParameters : {reformParameters}")
    # logger.debug(f"compute_reform - annee_de_calcul : {annee_de_calcul}")
    # logger.debug(f"compute_reform - prelevements_sociaux.contributions_sociales.csg.activite.deductible.taux : {tax_benefit_system.parameters.prelevements_sociaux.contributions_sociales.csg.activite.deductible.taux}")
    # Is result cached ?
    if cache.is_available():
        reform_hash = str(
            hashlib.sha224(reformParameters.json().encode("utf-8")).hexdigest()
        ) + str(annee_de_calcul)
        cached_result = cache.get(reform_hash)
        if cached_result is None:
            logger.debug(f"No cache for {reform_hash}, compute it.")
        else:
            logger.debug(f"Cache found for reformParameters {reform_hash}, return it.")
            # logger.debug(f"Cache for {reform_hash} : {cached_result}")
            return OneSimulationResult.parse_obj(json.loads(cached_result)), []
    # else:
    #    logger.warning("Redis not found : we do not use cache to speed up calculation")

    #     debut = timeit.default_timer()
    tbs_custom = CustomReform(tax_benefit_system, reformParameters, annee_de_calcul)
    # logger.debug(f"compute_reform - tbs_custom prelevements_sociaux.contributions_sociales.csg.activite.deductible.taux : {tbs_custom.parameters.prelevements_sociaux.contributions_sociales.csg.activite.deductible.taux}")

    # logger.debug(f"compute_reform for {annee_de_calcul} prelevements_sociaux.contributions_sociales.csg.activite.imposable.taux={tbs_custom.parameters(annee_de_calcul).prelevements_sociaux.contributions_sociales.csg.activite.imposable.taux}")
    #     logger.debug(
    #         f"Temps de création de la réforme : {timeit.default_timer() - debut} secondes"
    #     )
    #     debut_compute = timeit.default_timer()
    state_budget = {}
    data_for_quantile = {}
    variables_computed = []

    # Prepare simulation
    simulation, dictionnaire_datagrouped = create_simulation(
        period=annee_de_calcul, data=sample_pop, tbs=tbs_custom
    )

    for variable in reformParameters.output_variables:
        # Check if the variable are not already in the input dataset
        # only if not a base variable we use for quantile computation
        if (
            reformParameters.quantile_base_variable
            and variable not in ["rfr"] + reformParameters.quantile_base_variable
            and variable in dictionnaire_datagrouped["individu"].columns
        ):
            msg = f"The variable {variable} already exist in input data !"
            logger.warning(msg)
            errors.append(msg)
            return simu_out, errors
        resultat = simulation.calculate_add(variable, annee_de_calcul)
        # logger.debug(f"calculate_add : La somme de {variable} pour {annee_de_calcul} est {resultat.sum():,.0f}")
        if len(resultat) > len(sample_pop_foyer):
            # logger.debug("OpenFisca a retourné des individus")
            df_pop = sample_pop
        else:
            df_pop = sample_pop_foyer
        variable_result = np.absolute(resultat)
        if ignore_recallage:
            state_budget[variable] = (df_pop["wprm"] * variable_result).sum()
        else:
            # Do we have an aggregate for this variable ?
            factor_name = "factor_to_" + str(annee_de_calcul)
            factor = aggregates.get_aggregate(
                config.get("YEAR_ERFS"), variable, "ERFS", factor_name
            )
            if factor and not ignore_recallage:
                variable_result = variable_result * factor
                state_budget[variable] = (df_pop["wprm"] * variable_result).sum()
            else:
                state_budget[variable] = (df_pop["wprm"] * variable_result).sum()
                if variable not in ["assiette_csg_abattue"]:
                    msg = f"We do not have a correction factor for {config.get('YEAR_ERFS')}-{variable}-{factor_name}"
                    logger.warning(msg)
                    errors.append(msg)
        #             logger.debug(
        #                 f"compute_reform - result for {variable} : {state_budget[variable]:,.0f} "
        #             )
        if reformParameters.quantile_nb > 1:
            # TODO : Il faudrait harmoniser les sorties pour avoir le même nombre de lignes pour le calcul des quantiles
            data_for_quantile[variable] = variable_result
        variables_computed.append(variable)
    #         logger.debug(
    #             f"Temps de calcul sur la population de la variable {variable}: {timeit.default_timer() - debut_compute} secondes"
    #         )
    if reformParameters.quantile_nb > 1:
        # debut_quantiles = timeit.default_timer()
        # Remove variables that we do not have computed
        quantile_compare_variables = []
        for v in reformParameters.quantile_compare_variables:
            if v in variables_computed:
                quantile_compare_variables.append(v)
            else:
                if v in df_pop.columns:
                    data_for_quantile[v] = df_pop[v]
                else:
                    msg = f"Unable to find variable {v} in dataset !"
                    logger.error(msg)
                    raise SimulationError(msg)
        # Check length of data
        nb_lignes_quantile = None
        for col, val in data_for_quantile.items():
            if nb_lignes_quantile:
                if nb_lignes_quantile != len(val):
                    msg = f"Variable {v} has {len(val)} rows versus {nb_lignes_quantile} for previous variables. We can only compute quantiles on variables of same entity/lenght."
                    logger.error(msg)
                    raise SimulationError(msg)
            else:
                nb_lignes_quantile = len(val)

        data_for_quantile["wprm"] = df_pop["wprm"]
        sample_pop_new = pd.DataFrame(data_for_quantile)
        quantiles = compute_quantile(
            sample_pop_new,
            quantile_base_variable=reformParameters.quantile_base_variable,
            col_values=quantile_compare_variables,
            nb_quantiles=reformParameters.quantile_nb,
            only_above_zero=only_above_zero,
        )
        simu_out = OneSimulationResult(state_budget=state_budget, quantiles=quantiles)
    #         logger.debug(
    #             f"Temps de calcul des déciles : {timeit.default_timer() - debut_quantiles} secondes"
    #         )
    else:
        simu_out = OneSimulationResult(state_budget=state_budget)

    if cache.is_available():
        cache.set(reform_hash, simu_out.json())
    #     logger.debug(
    #         f"Temps de traitement total pour un échantillon de {len(df_pop)} : {timeit.default_timer() - debut} secondes"
    #     )

    return simu_out, errors


# Cell
def compute_all_simulation(
    reform: ReformeSocioFiscale, ignore_recallage=False
) -> AllSimulationResult:
    """
    ::reform:: ReformeSocioFiscale
    ::annee_de_calcul:: str
    """
    debut = timeit.default_timer()
    errors = []
    result = None
    try:
        # Avant le PLF
        reform_base = ReformeSocioFiscale(
            base=reform.base,
            amendement={},  # We want the base result
            output_variables=reform.output_variables,
            quantile_base_variable=reform.quantile_base_variable,
            quantile_nb=reform.quantile_nb,
            quantile_compare_variables=reform.quantile_compare_variables,
        )
        # Avec le PLF
        if reform.plf:
            reform_plf = ReformeSocioFiscale(
                base=reform.base,
                plf=reform.plf,
                amendement={},  # The PLF is in plf_2022 tax_benefit_system
                output_variables=reform.output_variables,
                quantile_nb=reform.quantile_nb,
                quantile_base_variable=reform.quantile_base_variable,
                quantile_compare_variables=reform.quantile_compare_variables,
            )
            base_result, tmp_errors = compute_reform(
                reform_base,
                annee_de_calcul=reform.base,
                ignore_recallage=ignore_recallage,
            )
            errors += tmp_errors
            plf_result, tmp_errors = compute_reform(
                reform_plf,
                annee_de_calcul=reform.plf,
                ignore_recallage=ignore_recallage,
                tax_benefit_system=plf_2022,
            )
            errors += tmp_errors
            amendement_result, tmp_errors = compute_reform(
                reform,
                annee_de_calcul=reform.plf,
                ignore_recallage=ignore_recallage,
                tax_benefit_system=plf_2022,
            )
            errors += tmp_errors
            result = {
                "base": base_result,
                "plf": plf_result,
                "amendement": amendement_result,
            }
        else:
            base_result, tmp_errors = compute_reform(
                reform_base,
                annee_de_calcul=reform.base,
                ignore_recallage=ignore_recallage,
            )
            errors += tmp_errors
            if reform.amendement:
                amendement_result, tmp_errors = compute_reform(
                    reform,
                    annee_de_calcul=reform.base,
                    ignore_recallage=ignore_recallage,
                )
                errors += tmp_errors
                result = {
                    "base": base_result,
                    "amendement": amendement_result,
                }
            else:
                result = {"base": base_result}
    except SimulationError as e:
        errors += [str(e)]
    logger.debug(
        f"Temps de traitement total pour la simulation {timeit.default_timer() - debut} secondes. Annee ERFS {config.get('YEAR_ERFS')} Annee TBS {reform.base}"
    )
    # Deduplicate errors
    errors = list(set(errors))
    res = AllSimulationResult(result=result, errors=errors)
    return res
