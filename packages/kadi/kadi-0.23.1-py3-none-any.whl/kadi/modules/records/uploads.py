# Copyright 2020 Karlsruhe Institute of Technology
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from mimetypes import guess_type

from flask import current_app

from .files import aquire_file_lock
from .files import get_custom_mimetype
from .models import Chunk
from .models import File
from kadi.ext.db import db
from kadi.lib.db import update_object
from kadi.lib.revisions.core import create_revision
from kadi.lib.storage.local import create_default_local_storage
from kadi.lib.utils import is_iterable
from kadi.lib.utils import signal_resource_change


def delete_upload(upload):
    """Delete an existing upload.

    This will mark the upload for deletion, i.e. the upload's state will be set to
    ``"inactive"``.

    :param upload: The upload to delete.
    """
    upload.state = "inactive"


def remove_uploads(uploads):
    """Remove multiple uploads from local storage.

    Note that this function may issue one or more database commits.

    :param uploads: A single :class:`.Upload` or an iterable of uploads.
    """

    if not is_iterable(uploads):
        uploads = [uploads]

    for upload in uploads:
        delete_upload(upload)
        db.session.commit()

        storage = upload.storage
        filepath = storage.create_filepath(str(upload.id))

        if filepath is not None:
            # Remove the chunks of the upload.
            for chunk in upload.chunks:
                chunk_filepath = f"{filepath}-{chunk.index}"
                storage.delete(chunk_filepath)

                db.session.delete(chunk)

            storage.delete(filepath)
            storage.remove_empty_parent_dirs(filepath)

            db.session.delete(upload)

        db.session.commit()


def save_chunk(*, upload, file_object, index, size, checksum=None):
    """Save a chunk of an upload.

    Each chunk uses the UUID of the given upload (see :attr:`.Upload.id`) combined with
    its index as base name in the form of ``"<uuid>-<index>"``. The complete path of the
    file will then be generated by prepending ``"STORAGE_PATH"`` as configured in the
    application's configuration.

    Note that this function issues one or more database commits.

    :param upload: The :class:`.Upload` the chunk belongs to.
    :param file_object: A file-like object representing the actual uploaded file.
    :param index: The index of the chunk.
    :param size: The size of the chunk in bytes.
    :param checksum: (optional) The MD5 checksum of the chunk. If given it will be used
        to verify the checksum after saving the chunk.
    :raises KadiFilesizeExceededError: If the chunk exceeds the chunk size configured in
        ``UPLOAD_CHUNK_SIZE`` in the application's configuration.
    :raises KadiFilesizeMismatchError: If the file size does not match the provided
        size.
    :raises KadiChecksumMismatchError: If the calculated checksum does not match the
        provided one.
    """
    chunk = Chunk.update_or_create(upload=upload, index=index, size=size)
    db.session.commit()

    storage = create_default_local_storage(
        max_size=current_app.config["UPLOAD_CHUNK_SIZE"]
    )

    filename = f"{upload.id}-{index}"
    filepath = storage.create_filepath(filename)

    try:
        storage.save(filepath, file_object)
        storage.validate_size(filepath, size)

        if checksum:
            storage.validate_checksum(filepath, checksum)

        chunk.state = "active"

    except:
        chunk.state = "inactive"
        raise

    finally:
        # Always update the upload's timestamp since the timestamp is used for the
        # expiration date.
        upload.update_timestamp()
        db.session.commit()


def merge_chunks(upload, task=None):
    """Merge the chunks of an upload.

    Uses :func:`complete_file_upload` to complete the file upload process.

    :param upload: The :class:`.Upload` the chunks belong to.
    :param task: (optional) A :class:`.Task` object that can be provided if this
        function is executed in a task. In that case, the progress of the given task
        will be updated.
    :return: The resulting new or updated local file or ``None`` if a file to be
        replaced by the upload has already been deleted.
    """
    storage = create_default_local_storage(
        max_size=current_app.config["MAX_UPLOAD_SIZE"],
    )
    upload_path = storage.create_filepath(str(upload.id))

    # Merge the uploaded chunks.
    chunks = upload.active_chunks.order_by(Chunk.index.asc())
    for index, chunk in enumerate(chunks):
        chunk_filepath = f"{upload_path}-{chunk.index}"
        storage.save(upload_path, chunk_filepath, append=True)

        if task is not None:
            task.update_progress((index + 1) / upload.chunk_count * 100)
            db.session.commit()

    return complete_file_upload(storage, upload)


def complete_file_upload(storage, upload):
    """Performs necessary steps to complete a file upload.

    Note that this function aquires a lock on the file being replaced by the given
    upload, if applicable, and issues one or more database commits or rollbacks.

    :param storage: The storage used to store the file.
    :param upload: The :class:`.Upload` the file belong to.
    :return: The resulting new or updated local file or ``None`` if a file to be
        replaced by the upload has already been deleted.
    :raises KadiFilesizeExceededError: If the file exceeds the file size configured in
        ``MAX_UPLOAD_SIZE`` in the application's configuration.
    :raises KadiFilesizeMismatchError: If the actual file size does not match the size
        of the file object.
    :raises KadiChecksumMismatchError: If the actual checksum does not match the
        checksum of the file object.
    """
    try:
        upload_path = storage.create_filepath(str(upload.id))

        storage.validate_size(upload_path, upload.size)

        checksum = upload.checksum
        calculated_checksum = upload.calculated_checksum

        if calculated_checksum is None:
            calculated_checksum = storage.get_checksum(upload_path)

        if checksum is not None:
            storage.validate_checksum(upload_path, checksum, actual=calculated_checksum)

        new_file_created = False

        # Check whether the upload replaces an existing file.
        if upload.file is None:
            file = File.create(
                creator=upload.creator,
                record=upload.record,
                name=upload.name,
                size=upload.size,
                checksum=calculated_checksum,
                storage=upload.storage,
            )
            # Commit here already, so the file can be referenced and deleted later if
            # something went wrong.
            db.session.commit()

            new_file_created = True
        else:
            # Lock the file to make sure replacing the metadata and actual file data
            # happens in a single transaction.
            file = aquire_file_lock(upload.file)

            # Check if the file still exists and is active.
            if file is None or file.state != "active":
                # Release the file lock.
                db.session.commit()
                return None

            update_object(file, size=upload.size, checksum=calculated_checksum)

        # Move the completed upload to the correct location.
        filepath = storage.create_filepath(str(file.id))
        storage.move(upload_path, filepath)

        # Determine the magic MIME type, and possibly a custom MIME type, based on the
        # file's content.
        base_mimetype = storage.get_mimetype(filepath)
        custom_mimetype = get_custom_mimetype(file, base_mimetype=base_mimetype)
        magic_mimetype = base_mimetype if custom_mimetype is None else custom_mimetype

        # Determine the regular MIME type. If no MIME type was given explicitly for the
        # upload, the custom MIME type is taken, if applicable. Otherwhise, try to guess
        # the regular MIME type from the filename and fall back to the magic MIME type.
        mimetype = upload.mimetype

        if mimetype == "application/octet-stream":
            if custom_mimetype is not None:
                mimetype = custom_mimetype
            else:
                mimetype = guess_type(file.name)[0] or magic_mimetype

        update_object(
            file, mimetype=mimetype, magic_mimetype=magic_mimetype, state="active"
        )

        update_timestamp = False
        if db.session.is_modified(file):
            update_timestamp = True

        # Note that the creator of the upload will be used for the revision. The
        # original creator of the file will stay the same.
        revision_created = create_revision(file, user=upload.creator)

        if update_timestamp:
            file.record.update_timestamp()

        upload.state = "inactive"

        # Releases the file lock as well.
        db.session.commit()

        if revision_created:
            signal_resource_change(file, user=upload.creator, created=new_file_created)

        return file

    except:
        db.session.rollback()

        # If something went wrong when replacing a file, check whether the old file is
        # still intact and delete it if not.
        if upload.file is not None:
            try:
                filepath = storage.create_filepath(str(upload.file.id))
                storage.validate_checksum(filepath, upload.file.checksum)
            except:
                from .files import delete_file

                delete_file(upload.file, revision_user=upload.creator)

        upload.state = "inactive"
        db.session.commit()
        raise
