{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd7b4f1",
   "metadata": {},
   "source": [
    "# Deep learning for HKL classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820328d7",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bc970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras library is required \n",
    "# \"conda install -c conda-forge keras\" for anaconda distribution\n",
    "# Currently CPU calculation is more than enough. GPU not really needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb7cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- OK! You are using python 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Keras import\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "## LaueTools import\n",
    "import LaueTools.dict_LaueTools as dictLT\n",
    "import LaueTools.findorient as FO\n",
    "import LaueTools.generaltools as GT\n",
    "import LaueTools.lauecore as LT\n",
    "import LaueTools.CrystalParameters as CP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a9d19",
   "metadata": {},
   "source": [
    "## Defining useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ddff046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_material_data(material_=\"Cu\", ang_maxx = 45, step = 0.5, hkl_ref=13, hklclass=11):\n",
    "    \"\"\"\n",
    "    simplified routine from LaueTools to get only the closest angles as output\n",
    "    For efficiency \n",
    "    To be simpler only Cubic materials are considered in the Following script\n",
    "    Easily extendable for other symmetries as well!\n",
    "    \"\"\"\n",
    "    a, b, c, alpha, beta, gamma = dictLT.dict_Materials[material_][1]\n",
    "    Gstar = CP.Gstar_from_directlatticeparams(a, b, c, alpha, beta, gamma)\n",
    "    rules = dictLT.dict_Materials[material_][-1]\n",
    "    \n",
    "    hkl2 = GT.threeindices_up_to(hkl_ref)\n",
    "    hkl2 = CP.ApplyExtinctionrules(hkl2,rules)\n",
    "\n",
    "    n = hklclass\n",
    "    classhkl = []\n",
    "    if material_ == \"Cu\":\n",
    "        for i in range(1,n+1):\n",
    "            for j in range(0,i+1):\n",
    "                for k in range(0,j+1):\n",
    "                    classhkl.append([i,j,k])\n",
    "        classhkl = np.array(classhkl)\n",
    "        classhkl = CP.ApplyExtinctionrules(classhkl, rules)\n",
    "        classhkl = CP.FilterHarmonics_2(classhkl)  \n",
    "        classhkl = np.array([classhkl_cubic(hkl) for hkl in classhkl])\n",
    "    #%\n",
    "    DEG = np.pi / 180.0\n",
    "    query_angle = ang_maxx/2.\n",
    "    angle_tol = ang_maxx/2.\n",
    "    hkl1 = classhkl\n",
    "    key_material = material_\n",
    "    dictmaterials=dictLT.dict_Materials\n",
    "    rules = (None, dictmaterials[key_material][2])\n",
    "    latticeparams = dictmaterials[key_material][1]\n",
    "    Gstar = CP.Gstar_from_directlatticeparams(*latticeparams)\n",
    "    # compute square matrix containing angles\n",
    "    metrics = Gstar\n",
    "    H1 = hkl1\n",
    "    n1 = hkl1.shape[0]\n",
    "    H2 = hkl2\n",
    "    n2 = hkl2.shape[0]\n",
    "    \n",
    "    dstar_square_1 = np.diag(np.inner(np.inner(H1, metrics), H1))\n",
    "    dstar_square_2 = np.diag(np.inner(np.inner(H2, metrics), H2))\n",
    "    scalar_product = np.inner(np.inner(H1, metrics), H2) * 1.0\n",
    "    \n",
    "    d1 = np.sqrt(dstar_square_1.reshape((n1, 1))) * 1.0\n",
    "    d2 = np.sqrt(dstar_square_2.reshape((n2, 1))) * 1.0\n",
    "    outy = np.outer(d1, d2)\n",
    "    \n",
    "    ratio = scalar_product / outy\n",
    "    ratio = np.round(ratio, decimals=7)\n",
    "    tab_angulardist = np.arccos(ratio) / DEG\n",
    "    \n",
    "    np.putmask(tab_angulardist, np.abs(tab_angulardist) < 0.001, 400)\n",
    "    \n",
    "    closest_angles_values = []\n",
    "    for ang_ in trange(len(tab_angulardist)):\n",
    "        tab_angulardist_ = tab_angulardist[ang_,:]\n",
    "        angles_set = np.ravel(tab_angulardist_)  # 1D array\n",
    "        sorted_ind = np.argsort(angles_set)\n",
    "        sorted_angles = angles_set[sorted_ind]\n",
    "        \n",
    "        angle_query = angle_tol\n",
    "        if isinstance(query_angle, (list, np.ndarray, tuple)):\n",
    "            angle_query = query_angle[0]\n",
    "        \n",
    "        array_angledist = np.abs(sorted_angles - angle_query)\n",
    "        pos_min = np.argmin(array_angledist)\n",
    "        closest_angle = sorted_angles[pos_min]\n",
    "        \n",
    "        if np.abs(closest_angle - query_angle) > angle_tol:\n",
    "            if angle_query > 0.5:\n",
    "                pass\n",
    "            print(\"Angle difference too low; take care here; no return\")\n",
    "            \n",
    "        condition = array_angledist <= angle_tol\n",
    "        closest_index_in_sorted_angles_raw = np.where(condition)[0]\n",
    "        closest_angles_values.append(np.take(sorted_angles, closest_index_in_sorted_angles_raw))\n",
    "    \n",
    "    codebars = []\n",
    "    angbins = np.arange(0,ang_maxx+step,step)\n",
    "    angbins = np.arange(0,ang_maxx+step,step)\n",
    "    angbins = np.arange(0,ang_maxx+step,step)\n",
    "    #gaussspacing = 1/np.exp(-(np.linspace(0,45,501)-25)**2/2/17**2)\n",
    "    #angbins = np.add.accumulate(gaussspacing)/420*45.\n",
    "    \n",
    "    for i in trange(len(closest_angles_values)):\n",
    "        angles = closest_angles_values[i]\n",
    "        fingerprint = np.histogram(angles, bins=angbins, density=False)[0]\n",
    "        codebars.append(fingerprint)\n",
    "    return codebars, angbins, classhkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e838c",
   "metadata": {},
   "source": [
    "## Function to simulate Laue Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83aacda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulatemultiplepatterns(n, seed=1234, key_material=None, emax=23,\n",
    "                             detectorparameters=None,\n",
    "                             sortintensity = False):\n",
    "    nbUBs=n\n",
    "    np.random.seed(seed)\n",
    "    UBelemagnles = np.random.random((3,nbUBs))*360-180.\n",
    "    l_tth, l_chi, l_miller_ind, l_posx, l_posy, l_E, l_intensity = [],[],[],[],[],[],[]\n",
    "    \n",
    "    for angle_X, angle_Y, angle_Z in UBelemagnles.T:\n",
    "        UBmatrix = GT.fromelemangles_toMatrix([angle_X, angle_Y, angle_Z])\n",
    "        grain = CP.Prepare_Grain(key_material, UBmatrix)\n",
    "\n",
    "        if detectorparameters is None:\n",
    "            detectorparameters = [70.182, 1039.309, 944.122, 0.747, 0.071]\n",
    "        s_tth, s_chi, s_miller_ind, s_posx, s_posy, s_E= LT.SimulateLaue_full_np(grain, 5, emax,\n",
    "                                                                                 detectorparameters,\n",
    "                                                                                 pixelsize=0.079142,\n",
    "                                                                                 removeharmonics=0)\n",
    "        s_intensity = 1./s_E\n",
    "        l_tth.append(s_tth)\n",
    "        l_chi.append(s_chi)\n",
    "        l_miller_ind.append(s_miller_ind)\n",
    "        l_posx.append(s_posx)\n",
    "        l_posy.append(s_posy)\n",
    "        l_E.append(s_E)\n",
    "        l_intensity.append(s_intensity)\n",
    "    #flat_list = [item for sublist in l for item in sublist]\n",
    "    s_tth = np.array([item for sublist in l_tth for item in sublist])\n",
    "    s_chi = np.array([item for sublist in l_chi for item in sublist])\n",
    "    s_miller_ind = np.array([item for sublist in l_miller_ind for item in sublist])\n",
    "    s_posx = np.array([item for sublist in l_posx for item in sublist])\n",
    "    s_posy = np.array([item for sublist in l_posy for item in sublist])\n",
    "    s_E = np.array([item for sublist in l_E for item in sublist])\n",
    "    s_intensity=np.array([item for sublist in l_intensity for item in sublist])\n",
    "    \n",
    "    if sortintensity:\n",
    "        indsort = np.argsort(s_intensity)[::-1]\n",
    "        s_tth=np.take(s_tth, indsort)\n",
    "        s_chi=np.take(s_chi, indsort)\n",
    "        s_miller_ind=np.take(s_miller_ind, indsort, axis=0)\n",
    "        s_posx=np.take(s_posx, indsort)\n",
    "        s_posy=np.take(s_posy, indsort)\n",
    "        s_E=np.take(s_E, indsort)\n",
    "        s_intensity=np.take(s_intensity, indsort)\n",
    "    return s_tth, s_chi, s_miller_ind,s_posx,s_posy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db8fe92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other helper funtions to limit the HKL indices\n",
    "def spots_in_ROI(s_tth,s_chi,centerscattering=[70/2.,0],anglefromcenter=10.):\n",
    "    \"\"\" return spot indices of spot lying in a given direction around a central direction\"\"\"\n",
    "    # finding central spots\n",
    "    s_the = s_tth/2.\n",
    "    exp_s = np.array([s_the,s_chi]).T\n",
    "    dist=GT.calculdist_from_thetachi(np.array([centerscattering]),exp_s).flatten()\n",
    "    conddistin = dist<=anglefromcenter\n",
    "    condtth = s_tth<70\n",
    "    cond = np.logical_and(conddistin,condtth)\n",
    "    #cond = np.logical_and(dist>anglefromcenter,condtth)\n",
    "    spots_ix= np.where(cond)[0]\n",
    "    return spots_ix\n",
    "\n",
    "def classhkl_cubic(hkl):\n",
    "    \"\"\" unique representation of hkl for cubic case\n",
    "    \"\"\"\n",
    "    return sorted([abs(int(ind)) for ind in hkl])\n",
    "\n",
    "def commonclass(hkl1, hkl2, material_):\n",
    "    \"\"\" test if hkl1 and hkl2 belong to the same class\"\"\"\n",
    "    if material_ == \"Cu\":\n",
    "        cond1 = classhkl_cubic(hkl1)==classhkl_cubic(hkl2)\n",
    "        cond2 = np.sum(np.cross(classhkl_cubic(hkl1),classhkl_cubic(hkl2))**2)==0.\n",
    "    return cond1 or cond2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8e572",
   "metadata": {},
   "source": [
    "## Function to prepare laue patterns with required inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e92c0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_LP(nbgrains, seednumber, material_,verbose,plotLauePattern):\n",
    "    s_tth, s_chi, s_miller_ind, s_posx,s_posy = simulatemultiplepatterns(nbgrains,\n",
    "                                                                        seed=seednumber,\n",
    "                                                                        key_material=material_,\n",
    "                                                                        sortintensity=True)\n",
    "    spots_in_center = spots_in_ROI(s_tth,s_chi)\n",
    "    if verbose:\n",
    "        print('nb of central spots',len(spots_in_center))\n",
    "        print('Central spots',spots_in_center)\n",
    "    \n",
    "    if plotLauePattern:\n",
    "        figlaue, axlaue= plt.subplots()\n",
    "        axlaue.scatter(s_tth,s_chi)\n",
    "        axlaue.scatter(s_tth[spots_in_center],s_chi[spots_in_center], c=\"r\")\n",
    "        axlaue.set_title('nb matrices: %d, nb spots : %d'%(nbgrains,len(s_tth)))\n",
    "    # considering all spots\n",
    "    allspots_the_chi = np.transpose(np.array([s_tth/2., s_chi]))\n",
    "    #print(\"Calculating all mutual angular distances of selected spots...\")\n",
    "    tabledistancerandom = np.transpose(GT.calculdist_from_thetachi(allspots_the_chi, allspots_the_chi))\n",
    "    # ground truth\n",
    "    hkl_sol = s_miller_ind\n",
    "    return tabledistancerandom, hkl_sol, spots_in_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a5a4c",
   "metadata": {},
   "source": [
    "## Define the architecture of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e62a65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_arch(trainX, trainy):\n",
    "    \"\"\"\n",
    "    Very simple and straight forward Neural Network with few hyperparameters\n",
    "    straighforward RELU activation strategy with cross entropy to identify the HKL\n",
    "    \"\"\"\n",
    "    n_bins, n_outputs = trainX.shape[1], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(keras.Input(shape=(n_bins,)))\n",
    "    model.add(Dense(n_bins, activation='selu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense((n_bins)//2, activation='selu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense((n_bins)//2, activation='selu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16b08b",
   "metadata": {},
   "source": [
    "# Lets train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de24396",
   "metadata": {},
   "source": [
    "## generate data for model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3412f7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [00:00<00:00, 1362.54it/s]\n",
      "100%|██████████| 378/378 [00:00<00:00, 20967.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 300) (378, 378)\n",
      "301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## we generate Cu HKL's upto 9 indices with max angle of 45° and binning of 0.1°\n",
    "## TODO include a multi binning dimensional data (i.e. with different binning strategy)\n",
    "codebars, angbins, classhkl = get_material_data(material_=\"Cu\", \\\n",
    "                                                   ang_maxx = 30, \\\n",
    "                                                   step = 0.1, \\\n",
    "                                                   hkl_ref=20, \\\n",
    "                                                   hklclass=20)\n",
    "trainX = np.array(codebars)\n",
    "#### Normalization-- Does not make significant difference\n",
    "max_codebars = np.max(trainX, axis = 1)\n",
    "trainX = trainX.T/ max_codebars\n",
    "trainX = trainX.T\n",
    "## convert HKL's to one hot encoding for NEURAL NETWORK (Also known as GROUND TRUTH)\n",
    "trainy = np.array([i for i in range(len(classhkl))])\n",
    "trainy = to_categorical(trainy)\n",
    "print(trainX.shape, trainy.shape)\n",
    "print(len(angbins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec12c7b",
   "metadata": {},
   "source": [
    "## Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97aeca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 378)               57078     \n",
      "=================================================================\n",
      "Total params: 215,178\n",
      "Trainable params: 215,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 6.3591 - accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 5.8786 - accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "378/378 [==============================] - 0s 505us/step - loss: 4.7179 - accuracy: 0.0714\n",
      "Epoch 4/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 3.0915 - accuracy: 0.3651\n",
      "Epoch 5/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.1871 - accuracy: 0.8069\n",
      "Epoch 6/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.3607 - accuracy: 0.9312\n",
      "Epoch 7/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.1815 - accuracy: 0.9524\n",
      "Epoch 8/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.1761 - accuracy: 0.9656\n",
      "Epoch 9/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 0.0997 - accuracy: 0.9841\n",
      "Epoch 10/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 0.1283 - accuracy: 0.9788\n",
      "Epoch 11/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 0.3876 - accuracy: 0.9048\n",
      "Epoch 12/1000\n",
      "378/378 [==============================] - 0s 510us/step - loss: 0.5761 - accuracy: 0.8413\n",
      "Epoch 13/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.4742 - accuracy: 0.8862\n",
      "Epoch 14/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 0.0345 - accuracy: 0.9894\n",
      "Epoch 15/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 0.0798 - accuracy: 0.9841\n",
      "Epoch 16/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 5.3614e-04 - accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 4.0710e-04 - accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 3.2915e-04 - accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 2.7413e-04 - accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "378/378 [==============================] - 0s 541us/step - loss: 2.3182e-04 - accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 1.9844e-04 - accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "378/378 [==============================] - 0s 516us/step - loss: 1.7027e-04 - accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 1.4683e-04 - accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.2666e-04 - accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 1.0931e-04 - accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 9.4346e-05 - accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 8.1365e-05 - accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 7.0155e-05 - accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 6.0459e-05 - accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 5.2019e-05 - accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 4.4626e-05 - accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "378/378 [==============================] - 0s 526us/step - loss: 3.8253e-05 - accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 3.2796e-05 - accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 2.8038e-05 - accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "378/378 [==============================] - 0s 511us/step - loss: 2.3984e-05 - accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "378/378 [==============================] - 0s 506us/step - loss: 2.0468e-05 - accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 1.7436e-05 - accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "378/378 [==============================] - 0s 511us/step - loss: 1.4807e-05 - accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 1.2552e-05 - accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 1.0627e-05 - accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 9.0198e-06 - accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 7.6000e-06 - accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 6.3982e-06 - accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 5.3817e-06 - accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 4.5208e-06 - accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 3.7781e-06 - accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 3.1430e-06 - accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 2.6330e-06 - accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 2.2003e-06 - accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "378/378 [==============================] - 0s 501us/step - loss: 1.8342e-06 - accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "378/378 [==============================] - 0s 501us/step - loss: 1.5251e-06 - accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "378/378 [==============================] - 0s 501us/step - loss: 1.2675e-06 - accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 1.0505e-06 - accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 8.6379e-07 - accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 7.1841e-07 - accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 5.8816e-07 - accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "378/378 [==============================] - 0s 526us/step - loss: 4.9355e-07 - accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 4.0336e-07 - accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 3.2956e-07 - accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 2.7942e-07 - accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.2738e-07 - accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 1.8197e-07 - accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.5264e-07 - accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "378/378 [==============================] - 0s 551us/step - loss: 1.2930e-07 - accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.0943e-07 - accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 9.1141e-08 - accuracy: 1.0000\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 525us/step - loss: 8.1365e-08 - accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "378/378 [==============================] - 0s 546us/step - loss: 7.3165e-08 - accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 7.3481e-08 - accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 6.7173e-08 - accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 8.3888e-08 - accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.5566 - accuracy: 0.7063\n",
      "Epoch 74/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.7456 - accuracy: 0.4603\n",
      "Epoch 75/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 0.2602 - accuracy: 0.9392\n",
      "Epoch 76/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.0881 - accuracy: 0.9788\n",
      "Epoch 77/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 0.0097 - accuracy: 0.9974\n",
      "Epoch 78/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 5.2130e-04 - accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 2.9534e-04 - accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "378/378 [==============================] - 0s 527us/step - loss: 2.3483e-04 - accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 1.9200e-04 - accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 1.5959e-04 - accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 1.3394e-04 - accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 1.1328e-04 - accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 9.6294e-05 - accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 8.2485e-05 - accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 7.0533e-05 - accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 6.0452e-05 - accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 5.1830e-05 - accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 4.4497e-05 - accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 3.8176e-05 - accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 3.2782e-05 - accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 2.8153e-05 - accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 2.4156e-05 - accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 2.0747e-05 - accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.7755e-05 - accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 1.5166e-05 - accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.2950e-05 - accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.1048e-05 - accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 9.4247e-06 - accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 8.0267e-06 - accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "378/378 [==============================] - 0s 565us/step - loss: 6.8204e-06 - accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "378/378 [==============================] - 0s 541us/step - loss: 5.8043e-06 - accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 4.9355e-06 - accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 4.1824e-06 - accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "378/378 [==============================] - 0s 544us/step - loss: 3.5378e-06 - accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 2.9827e-06 - accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 2.5147e-06 - accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 2.1152e-06 - accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 1.7853e-06 - accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 1.4911e-06 - accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 1.2526e-06 - accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 1.0489e-06 - accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 8.6979e-07 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 7.2976e-07 - accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 6.1181e-07 - accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 5.0112e-07 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 4.1723e-07 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "378/378 [==============================] - 0s 511us/step - loss: 3.4060e-07 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 2.8415e-07 - accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 2.3369e-07 - accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.9364e-07 - accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.5989e-07 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 1.2930e-07 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "378/378 [==============================] - 0s 505us/step - loss: 1.0249e-07 - accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 8.6411e-08 - accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 7.3481e-08 - accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 6.1812e-08 - accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 4.9828e-08 - accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 4.6359e-08 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "378/378 [==============================] - 0s 503us/step - loss: 4.1313e-08 - accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 4.3205e-08 - accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 3.7213e-08 - accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 4.5728e-08 - accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 2.8919 - accuracy: 0.5952\n",
      "Epoch 136/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 2.2885 - accuracy: 0.5529\n",
      "Epoch 137/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 0.2227 - accuracy: 0.9524\n",
      "Epoch 138/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 139/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 0.1776 - accuracy: 0.9762\n",
      "Epoch 140/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 3.1784e-04 - accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 2.4783e-04 - accuracy: 1.0000\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 512us/step - loss: 1.9883e-04 - accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 1.6216e-04 - accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 1.3402e-04 - accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 1.1137e-04 - accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "378/378 [==============================] - 0s 526us/step - loss: 9.3261e-05 - accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 7.8420e-05 - accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 6.6288e-05 - accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 5.6215e-05 - accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 4.7649e-05 - accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 4.0553e-05 - accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 3.4522e-05 - accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 2.9405e-05 - accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 2.5054e-05 - accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 2.1324e-05 - accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.8137e-05 - accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 1.5425e-05 - accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 1.3118e-05 - accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "378/378 [==============================] - 0s 526us/step - loss: 1.1151e-05 - accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 9.4944e-06 - accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "378/378 [==============================] - 0s 546us/step - loss: 8.0566e-06 - accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 6.8387e-06 - accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 5.8018e-06 - accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "378/378 [==============================] - 0s 526us/step - loss: 4.9040e-06 - accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "378/378 [==============================] - 0s 532us/step - loss: 4.1584e-06 - accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "378/378 [==============================] - 0s 532us/step - loss: 3.5138e-06 - accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "378/378 [==============================] - 0s 532us/step - loss: 2.9859e-06 - accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 2.5185e-06 - accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 2.1180e-06 - accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.7847e-06 - accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 1.4933e-06 - accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 1.2593e-06 - accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 1.0555e-06 - accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 8.7862e-07 - accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "378/378 [==============================] - 0s 523us/step - loss: 7.3039e-07 - accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "378/378 [==============================] - 0s 497us/step - loss: 6.1308e-07 - accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 5.0680e-07 - accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "378/378 [==============================] - 0s 506us/step - loss: 4.2575e-07 - accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 3.5479e-07 - accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 2.9203e-07 - accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 2.4063e-07 - accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.9616e-07 - accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 1.6305e-07 - accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "378/378 [==============================] - 0s 516us/step - loss: 1.3340e-07 - accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 1.0912e-07 - accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 8.7042e-08 - accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 7.0958e-08 - accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 5.6136e-08 - accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "378/378 [==============================] - 0s 506us/step - loss: 4.7621e-08 - accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 3.7844e-08 - accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 3.6583e-08 - accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 3.2483e-08 - accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 2.4599e-08 - accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 3.0906e-08 - accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "378/378 [==============================] - 0s 535us/step - loss: 2.2391e-08 - accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 2.6176e-08 - accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 3.0591e-08 - accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 2.5953 - accuracy: 0.5873\n",
      "Epoch 200/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 2.4866 - accuracy: 0.5503\n",
      "Epoch 201/1000\n",
      "378/378 [==============================] - 0s 511us/step - loss: 0.2569 - accuracy: 0.9365\n",
      "Epoch 202/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 0.1081 - accuracy: 0.9683\n",
      "Epoch 203/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 0.0642 - accuracy: 0.9762\n",
      "Epoch 204/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 0.0476 - accuracy: 0.9894\n",
      "Epoch 205/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 0.1256 - accuracy: 0.9709\n",
      "Epoch 206/1000\n",
      "378/378 [==============================] - 0s 550us/step - loss: 0.3764 - accuracy: 0.8995\n",
      "Epoch 207/1000\n",
      "378/378 [==============================] - 0s 511us/step - loss: 0.4604 - accuracy: 0.9074\n",
      "Epoch 208/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.2872 - accuracy: 0.9180\n",
      "Epoch 209/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 0.2474 - accuracy: 0.9524\n",
      "Epoch 210/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 0.3498 - accuracy: 0.9233\n",
      "Epoch 211/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 0.3414 - accuracy: 0.9206\n",
      "Epoch 212/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 0.1605 - accuracy: 0.9735\n",
      "Epoch 213/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 0.0772 - accuracy: 0.9788\n",
      "Epoch 214/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 0.1663 - accuracy: 0.9709\n",
      "Epoch 215/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 0.3817 - accuracy: 0.9365\n",
      "Epoch 216/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.4097 - accuracy: 0.9339\n",
      "Epoch 217/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 0.3180 - accuracy: 0.9312\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 511us/step - loss: 0.1862 - accuracy: 0.9656\n",
      "Epoch 219/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 0.0979 - accuracy: 0.9788\n",
      "Epoch 220/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 0.0051 - accuracy: 0.9974\n",
      "Epoch 221/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 1.4799e-05 - accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 9.9272e-06 - accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 8.2946e-06 - accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 7.1880e-06 - accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 6.3530e-06 - accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 5.6275e-06 - accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 5.0173e-06 - accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 4.4819e-06 - accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 3.9940e-06 - accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 3.5383e-06 - accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 3.1344e-06 - accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 2.7717e-06 - accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 2.4450e-06 - accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 2.1593e-06 - accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "378/378 [==============================] - 0s 506us/step - loss: 1.8843e-06 - accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 1.6459e-06 - accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 1.4340e-06 - accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.2473e-06 - accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 1.0798e-06 - accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 9.3096e-07 - accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 8.0135e-07 - accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 6.9412e-07 - accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "378/378 [==============================] - 0s 532us/step - loss: 5.9163e-07 - accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 5.0585e-07 - accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 4.3426e-07 - accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 3.6835e-07 - accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 3.1505e-07 - accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.6806e-07 - accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.2707e-07 - accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.9143e-07 - accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "378/378 [==============================] - 0s 527us/step - loss: 1.6241e-07 - accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.3719e-07 - accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.1574e-07 - accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 9.7449e-08 - accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 8.1365e-08 - accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 6.8120e-08 - accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 5.6136e-08 - accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 4.5728e-08 - accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 3.8790e-08 - accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 3.1221e-08 - accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 2.6806e-08 - accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.0499e-08 - accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 1.5453e-08 - accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 1.2930e-08 - accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 9.4611e-09 - accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 8.5149e-09 - accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 6.9381e-09 - accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 5.0459e-09 - accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.8383e-09 - accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 1.5768e-09 - accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "378/378 [==============================] - 0s 503us/step - loss: 1.5768e-09 - accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.5768e-09 - accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 9.4611e-10 - accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 9.4611e-10 - accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 1.2615e-09 - accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 9.4611e-10 - accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 1.8922e-09 - accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 3.1537e-10 - accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 1.2615e-09 - accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 9.4611e-10 - accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 1.5768e-09 - accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.2615e-09 - accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 2.5229e-09 - accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "378/378 [==============================] - 0s 501us/step - loss: 1.5768e-09 - accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 507us/step - loss: 1.8922e-09 - accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 9.4611e-10 - accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 1.1572 - accuracy: 0.8624\n",
      "Epoch 295/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 2.2627 - accuracy: 0.6481\n",
      "Epoch 296/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 0.2896 - accuracy: 0.9418\n",
      "Epoch 297/1000\n",
      "378/378 [==============================] - 0s 501us/step - loss: 0.1155 - accuracy: 0.9841\n",
      "Epoch 298/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 0.0232 - accuracy: 0.9894\n",
      "Epoch 299/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 0.0770 - accuracy: 0.9815\n",
      "Epoch 300/1000\n",
      "378/378 [==============================] - 0s 507us/step - loss: 0.0049 - accuracy: 0.9974\n",
      "Epoch 301/1000\n",
      "378/378 [==============================] - 0s 518us/step - loss: 1.5794e-05 - accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 1.3145e-05 - accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 1.1157e-05 - accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 9.5550e-06 - accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 8.2377e-06 - accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 7.1265e-06 - accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 6.1828e-06 - accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 5.3610e-06 - accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 4.6269e-06 - accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "378/378 [==============================] - 0s 538us/step - loss: 3.9991e-06 - accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 3.4604e-06 - accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "378/378 [==============================] - 0s 526us/step - loss: 2.9824e-06 - accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 2.5746e-06 - accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "378/378 [==============================] - 0s 526us/step - loss: 2.2082e-06 - accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 1.8969e-06 - accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.6330e-06 - accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 1.3986e-06 - accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "378/378 [==============================] - 0s 511us/step - loss: 1.1993e-06 - accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 1.0234e-06 - accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 8.7357e-07 - accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 7.4332e-07 - accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 6.3326e-07 - accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "378/378 [==============================] - 0s 513us/step - loss: 5.3833e-07 - accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "378/378 [==============================] - 0s 531us/step - loss: 4.6075e-07 - accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 3.9137e-07 - accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 3.3177e-07 - accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 2.8383e-07 - accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 2.3905e-07 - accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.0562e-07 - accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "378/378 [==============================] - 0s 578us/step - loss: 1.7282e-07 - accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "378/378 [==============================] - 0s 543us/step - loss: 1.4696e-07 - accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "378/378 [==============================] - 0s 559us/step - loss: 1.2394e-07 - accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 1.0502e-07 - accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 8.9565e-08 - accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 7.5688e-08 - accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 6.3704e-08 - accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "378/378 [==============================] - 0s 516us/step - loss: 5.4874e-08 - accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 4.6359e-08 - accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 3.7529e-08 - accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 3.1221e-08 - accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 2.3968e-08 - accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "378/378 [==============================] - 0s 505us/step - loss: 1.9553e-08 - accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "378/378 [==============================] - 0s 505us/step - loss: 1.3561e-08 - accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.0723e-08 - accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 9.1457e-09 - accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "378/378 [==============================] - 0s 531us/step - loss: 7.2535e-09 - accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 5.9920e-09 - accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 5.0459e-09 - accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 1.5768e-09 - accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 1.2615e-09 - accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 3.1537e-10 - accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "378/378 [==============================] - 0s 506us/step - loss: 3.1537e-10 - accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 3.1537e-10 - accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "378/378 [==============================] - 0s 511us/step - loss: 3.1537e-10 - accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "378/378 [==============================] - 0s 516us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 3.1537e-10 - accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "378/378 [==============================] - 0s 519us/step - loss: 9.4611e-10 - accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "378/378 [==============================] - 0s 525us/step - loss: 1.5768e-09 - accuracy: 1.0000\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 528us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 6.3074e-10 - accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "378/378 [==============================] - 0s 524us/step - loss: 7.2535e-09 - accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "378/378 [==============================] - 0s 536us/step - loss: 2.4353 - accuracy: 0.7381\n",
      "Epoch 370/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 1.8681 - accuracy: 0.7381\n",
      "Epoch 371/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 0.1946 - accuracy: 0.9603\n",
      "Epoch 372/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 0.0405 - accuracy: 0.9894\n",
      "Epoch 373/1000\n",
      "378/378 [==============================] - 0s 619us/step - loss: 4.7660e-04 - accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "378/378 [==============================] - 0s 654us/step - loss: 4.6600e-05 - accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "378/378 [==============================] - 0s 554us/step - loss: 3.6153e-05 - accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 2.9274e-05 - accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "378/378 [==============================] - 0s 517us/step - loss: 2.4261e-05 - accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 2.0447e-05 - accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "378/378 [==============================] - 0s 504us/step - loss: 1.7390e-05 - accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "378/378 [==============================] - 0s 512us/step - loss: 1.4854e-05 - accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.2749e-05 - accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.0973e-05 - accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 9.4621e-06 - accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 8.1112e-06 - accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 7.0120e-06 - accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 6.0483e-06 - accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 5.2110e-06 - accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 4.4835e-06 - accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 3.8578e-06 - accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 3.3189e-06 - accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "378/378 [==============================] - 0s 522us/step - loss: 2.8424e-06 - accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "378/378 [==============================] - 0s 508us/step - loss: 2.4343e-06 - accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "378/378 [==============================] - 0s 552us/step - loss: 2.0858e-06 - accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "378/378 [==============================] - 0s 536us/step - loss: 1.7869e-06 - accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "378/378 [==============================] - 0s 523us/step - loss: 1.5194e-06 - accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "378/378 [==============================] - 0s 509us/step - loss: 1.2981e-06 - accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "378/378 [==============================] - 0s 521us/step - loss: 1.1060e-06 - accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "378/378 [==============================] - 0s 528us/step - loss: 9.3948e-07 - accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 7.9504e-07 - accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "378/378 [==============================] - 0s 530us/step - loss: 6.7205e-07 - accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "378/378 [==============================] - 0s 514us/step - loss: 5.6577e-07 - accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "378/378 [==============================] - 0s 515us/step - loss: 4.7715e-07 - accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "378/378 [==============================] - 0s 532us/step - loss: 4.0241e-07 - accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "378/378 [==============================] - 0s 533us/step - loss: 3.3871e-07 - accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "378/378 [==============================] - 0s 551us/step - loss: 2.8415e-07 - accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "378/378 [==============================] - 0s 520us/step - loss: 2.3716e-07 - accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "  1/378 [..............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# try varying batch size and epochs\n",
    "epochs = 1000\n",
    "batch_size = 1\n",
    "verbose = 1\n",
    "model = model_arch(trainX, trainy)\n",
    "# fit network\n",
    "stats_model = model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, shuffle=1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c07e97",
   "metadata": {},
   "source": [
    "## Plot the losses and accuracy of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70a6ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7148514986038208\n",
      "Loss:  0.7245466709136963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23671d14850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( \"Accuracy: \", stats_model.history['accuracy'][-1])\n",
    "print( \"Loss: \", stats_model.history['loss'][-1])\n",
    "\n",
    "epochs = range(1, len(model.history.history['loss']) + 1)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(epochs, model.history.history['loss'], 'r', label='Training loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, model.history.history['accuracy'], 'g', label='Training Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f964c",
   "metadata": {},
   "source": [
    "# Prediction time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a3be2",
   "metadata": {},
   "source": [
    "## single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "793d4732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is BAD\n",
      "Actual HKL is [-1 -5 -3]\n",
      "Predicted HKL is [19 13  9]\n",
      "**********************************\n"
     ]
    }
   ],
   "source": [
    "nbgrains = 1\n",
    "material_ = \"Cu\"\n",
    "verbose = 0\n",
    "\n",
    "seednumber = np.random.randint(10000000)\n",
    "\n",
    "tabledistancerandom, hkl_sol, spots_in_center = prepare_LP(nbgrains, \n",
    "                                                            seednumber, \n",
    "                                                            material_,\n",
    "                                                            verbose,\n",
    "                                                            plotLauePattern=False)\n",
    "if len(spots_in_center) == 0:\n",
    "    print(\"No spots in center\")\n",
    "    \n",
    "for i in spots_in_center: ## identify the center HKL spots \n",
    "    spotangles = tabledistancerandom[i]\n",
    "    spotangles = np.delete(spotangles, i)# removing the self distance\n",
    "    codebars = np.histogram(spotangles, bins=angbins)[0]\n",
    "    max_codebars = np.max(codebars)\n",
    "    codebars = codebars/ max_codebars\n",
    "    codebars = codebars.reshape((1,len(codebars)))\n",
    "    ## prediction routine here\n",
    "    prediction = model.predict(codebars)\n",
    "    class_predicted = np.argmax(prediction, axis = 1)\n",
    "    ## verify prediction\n",
    "    isgoodprediction = commonclass(classhkl[class_predicted][0],hkl_sol[i],material_)\n",
    "    if isgoodprediction:\n",
    "        print(\"Prediction is GOOD\")\n",
    "    elif not isgoodprediction:\n",
    "        print(\"Prediction is BAD\")\n",
    "    print(\"Actual HKL is \"+ str(hkl_sol[i]))\n",
    "    print(\"Predicted HKL is \"+ str(classhkl[class_predicted][0]))\n",
    "    print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76ac1e",
   "metadata": {},
   "source": [
    "## Batch prediction to get some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b342379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 28.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********\n",
      "Total Prediction:  132\n",
      "GOOD Prediction:  39\n",
      "BAD Prediction:  93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nbgrains = 1\n",
    "material_ = \"Cu\"\n",
    "verbose = 0\n",
    "nbtestspots = 0\n",
    "nb_goods = 0\n",
    "nb_wrongs = 0\n",
    "bad_prediction_hkl = []\n",
    "\n",
    "for _ in trange(100):\n",
    "    seednumber = np.random.randint(10000000)\n",
    "\n",
    "    tabledistancerandom, hkl_sol, spots_in_center = prepare_LP(nbgrains, \n",
    "                                                                seednumber, \n",
    "                                                                material_,\n",
    "                                                                verbose,\n",
    "                                                                plotLauePattern=False)\n",
    "    nbtestspots = nbtestspots + len(spots_in_center)\n",
    "    for i in spots_in_center: ## identify the center HKL spots \n",
    "        spotangles = tabledistancerandom[i]\n",
    "        spotangles = np.delete(spotangles, i)# removing the self distance\n",
    "        codebars = np.histogram(spotangles, bins=angbins)[0]\n",
    "        max_codebars = np.max(codebars)\n",
    "        codebars = codebars/ max_codebars\n",
    "        codebars = codebars.reshape((1,len(codebars)))\n",
    "        \n",
    "        prediction = model.predict(codebars)\n",
    "        class_predicted = np.argmax(prediction, axis = 1)\n",
    "        \n",
    "        isgoodprediction = commonclass(classhkl[class_predicted][0],hkl_sol[i],material_)\n",
    "        if isgoodprediction:\n",
    "            nb_goods += 1\n",
    "        elif not isgoodprediction:\n",
    "            nb_wrongs += 1\n",
    "            bad_prediction_hkl.append((classhkl[class_predicted][0], hkl_sol[i]))\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"Actual HKL is \"+ str(hkl_sol[i]))\n",
    "            print(\"Predicted HKL is \"+ str(classhkl[class_predicted][0]))\n",
    "            print('goodprediction ',isgoodprediction)\n",
    "            print(\"**********************************\")\n",
    "        \n",
    "print(\"***********\")        \n",
    "print('Total Prediction: ',nbtestspots) \n",
    "print('GOOD Prediction: ',nb_goods)    \n",
    "print('BAD Prediction: ',nb_wrongs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b298a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
